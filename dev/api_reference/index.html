<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>References · LLMTextAnalysis.jl</title><meta name="title" content="References · LLMTextAnalysis.jl"/><meta property="og:title" content="References · LLMTextAnalysis.jl"/><meta property="twitter:title" content="References · LLMTextAnalysis.jl"/><meta name="description" content="Documentation for LLMTextAnalysis.jl."/><meta property="og:description" content="Documentation for LLMTextAnalysis.jl."/><meta property="twitter:description" content="Documentation for LLMTextAnalysis.jl."/><meta property="og:url" content="https://svilupp.github.io/LLMTextAnalysis.jl/api_reference/"/><meta property="twitter:url" content="https://svilupp.github.io/LLMTextAnalysis.jl/api_reference/"/><link rel="canonical" href="https://svilupp.github.io/LLMTextAnalysis.jl/api_reference/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">LLMTextAnalysis.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/1_topics_in_city_of_austin_community_survey/">Explore Topics in Your Documents</a></li><li><a class="tocitem" href="../examples/2_concept_labeling_in_city_of_austin_community_survey/">Look for specific Concept/Spectrum</a></li><li><a class="tocitem" href="../examples/3_customize_topic_labels/">Customize Topic Labels</a></li><li><a class="tocitem" href="../examples/4_classify_documents/">Classify Your Documents</a></li></ul></li><li><a class="tocitem" href="../FAQ/">F.A.Q.</a></li><li class="is-active"><a class="tocitem" href>References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>References</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>References</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/svilupp/LLMTextAnalysis.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/main/docs/src/api_reference.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h1><ul><li><a href="#LLMTextAnalysis.DocIndex"><code>LLMTextAnalysis.DocIndex</code></a></li><li><a href="#LLMTextAnalysis.NoStemmer"><code>LLMTextAnalysis.NoStemmer</code></a></li><li><a href="#LLMTextAnalysis.TopicMetadata"><code>LLMTextAnalysis.TopicMetadata</code></a></li><li><a href="#LLMTextAnalysis.TrainedClassifier"><code>LLMTextAnalysis.TrainedClassifier</code></a></li><li><a href="#LLMTextAnalysis.TrainedClassifier-Tuple{LLMTextAnalysis.AbstractDocumentIndex}"><code>LLMTextAnalysis.TrainedClassifier</code></a></li><li><a href="#LLMTextAnalysis.TrainedConcept"><code>LLMTextAnalysis.TrainedConcept</code></a></li><li><a href="#LLMTextAnalysis.TrainedConcept-Tuple{LLMTextAnalysis.AbstractDocumentIndex}"><code>LLMTextAnalysis.TrainedConcept</code></a></li><li><a href="#LLMTextAnalysis.TrainedSpectrum-Tuple{LLMTextAnalysis.AbstractDocumentIndex}"><code>LLMTextAnalysis.TrainedSpectrum</code></a></li><li><a href="#LLMTextAnalysis.TrainedSpectrum"><code>LLMTextAnalysis.TrainedSpectrum</code></a></li><li><a href="#LLMTextAnalysis.build_clusters!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, Vector{Int64}}"><code>LLMTextAnalysis.build_clusters!</code></a></li><li><a href="#LLMTextAnalysis.build_clusters!-Tuple{LLMTextAnalysis.AbstractDocumentIndex}"><code>LLMTextAnalysis.build_clusters!</code></a></li><li><a href="#LLMTextAnalysis.build_clusters!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedClassifier}"><code>LLMTextAnalysis.build_clusters!</code></a></li><li><a href="#LLMTextAnalysis.build_index-Tuple{Vector{&lt;:AbstractString}}"><code>LLMTextAnalysis.build_index</code></a></li><li><a href="#LLMTextAnalysis.build_keywords"><code>LLMTextAnalysis.build_keywords</code></a></li><li><a href="#LLMTextAnalysis.build_topic-Tuple{LLMTextAnalysis.AbstractDocumentIndex, Vector{Int64}, Int64}"><code>LLMTextAnalysis.build_topic</code></a></li><li><a href="#LLMTextAnalysis.create_folds-Tuple{Integer, Integer}"><code>LLMTextAnalysis.create_folds</code></a></li><li><a href="#LLMTextAnalysis.cross_validate_accuracy-Tuple{AbstractMatrix, AbstractVector{&lt;:Integer}}"><code>LLMTextAnalysis.cross_validate_accuracy</code></a></li><li><a href="#LLMTextAnalysis.nunique-Tuple{AbstractVector}"><code>LLMTextAnalysis.nunique</code></a></li><li><a href="#LLMTextAnalysis.prepare_plot!-Tuple{LLMTextAnalysis.AbstractDocumentIndex}"><code>LLMTextAnalysis.prepare_plot!</code></a></li><li><a href="#LLMTextAnalysis.score-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedClassifier}"><code>LLMTextAnalysis.score</code></a></li><li><a href="#LLMTextAnalysis.score-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedConcept}"><code>LLMTextAnalysis.score</code></a></li><li><a href="#LLMTextAnalysis.score-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedSpectrum}"><code>LLMTextAnalysis.score</code></a></li><li><a href="#LLMTextAnalysis.train!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedConcept}"><code>LLMTextAnalysis.train!</code></a></li><li><a href="#LLMTextAnalysis.train!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedSpectrum}"><code>LLMTextAnalysis.train!</code></a></li><li><a href="#LLMTextAnalysis.train!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedClassifier}"><code>LLMTextAnalysis.train!</code></a></li><li><a href="#LLMTextAnalysis.train_classifier-Tuple{LLMTextAnalysis.AbstractDocumentIndex, AbstractVector{&lt;:AbstractString}}"><code>LLMTextAnalysis.train_classifier</code></a></li><li><a href="#LLMTextAnalysis.train_concept-Tuple{LLMTextAnalysis.AbstractDocumentIndex, String}"><code>LLMTextAnalysis.train_concept</code></a></li><li><a href="#LLMTextAnalysis.train_spectrum-Tuple{LLMTextAnalysis.AbstractDocumentIndex, Tuple{String, String}}"><code>LLMTextAnalysis.train_spectrum</code></a></li><li><a href="#LLMTextAnalysis.wrap_string"><code>LLMTextAnalysis.wrap_string</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.DocIndex" href="#LLMTextAnalysis.DocIndex"><code>LLMTextAnalysis.DocIndex</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DocIndex{T1&lt;:AbstractString, T2&lt;:AbstractMatrix} &lt;: AbstractDocumentIndex</code></pre><p>A struct for maintaining an index of documents, their embeddings, and related information.</p><p><strong>Fields</strong></p><ul><li><code>id::Symbol</code>: Unique identifier for the document index.</li><li><code>docs::Vector{T1}</code>: Collection of documents.</li><li><code>embeddings::Matrix{Float32}</code>: Embeddings of the documents. Documents are columns.</li><li><code>distances::Matrix{Float32}</code>: Pairwise distances between document embeddings. Documents are columns.</li><li><code>keywords_ids::T2</code>: Sparse matrix representing keywords in documents. Keywords in <code>keywords_vocab</code> are rows, documents are columns.</li><li><code>keywords_vocab::Vector{&lt;:AbstractString}</code>: Vocabulary of keywords.</li><li><code>plot_data::Union{Nothing, Matrix{Float32}}</code>: 2D embedding data for plotting. Rows are dimensions, columns are documents.</li><li><code>clustering::Any</code>: Results of clustering the documents.</li><li><code>topic_levels::Dict{Union{AbstractString, Int}, Vector{TopicMetadata}}</code>: Metadata for topics at different levels.   Indexed by <code>k</code> = number of topics if autogenerated or via <code>topic_level</code> keyword if manually set via <code>build_clusters!</code> (eg, from a classifier).</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">docs = [&quot;Document 1 text&quot;, &quot;Document 2 text&quot;]
index = DocIndex(docs=docs, embeddings=rand(Float32, (10, 2)), distances=rand(Float32, (2, 2)))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/types.jl#L46-L68">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.NoStemmer" href="#LLMTextAnalysis.NoStemmer"><code>LLMTextAnalysis.NoStemmer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NoStemmer</code></pre><p>A dummy stemmer used as a workaround for bypassing stemming in keyword extraction. </p><p><strong>Example</strong></p><pre><code class="language-julia hljs">Snowball.stem(NoStemmer(), [&quot;running&quot;, &quot;jumps&quot;]) # returns [&quot;running&quot;, &quot;jumps&quot;]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/types.jl#L302-L311">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.TopicMetadata" href="#LLMTextAnalysis.TopicMetadata"><code>LLMTextAnalysis.TopicMetadata</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TopicMetadata &lt;: AbstractTopicMetadata</code></pre><p>A struct representing the metadata of a specific topic extracted from a collection of documents.</p><p><strong>Fields</strong></p><ul><li><code>index_id::Symbol</code>: Identifier for the topic.</li><li><code>topic_level::Union{AbstractString, Int}</code>: The level of the topic in the hierarchy.</li><li><code>topic_idx::Int</code>: Index of the topic.</li><li><code>label::AbstractString</code>: Human-readable label of the topic. Defaults to <code>&quot;&quot;</code>.</li><li><code>summary::AbstractString</code>: Brief summary of the topic. Defaults to <code>&quot;&quot;</code>.</li><li><code>docs_idx::Vector{Int}</code>: Indices of documents belonging to this topic. Corresponds to positions in <code>index.docs</code>.</li><li><code>center_doc_idx::Int</code>: Index of the central document in this topic. Corresponds to a position in <code>docs_idx</code> (not index!)</li><li><code>samples_doc_idx::Vector{Int}</code>: Indices of representative documents. Corresponds to positions in <code>docs_idx</code> (not index!)</li><li><code>keywords_idx::Vector{Int}</code>: Indices of specific keywords associated with this topic. Corresponds to positions in <code>index.keywords_vocab</code>.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">topic = TopicMetadata(topic_level=1, topic_idx=5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/types.jl#L7-L27">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.TrainedClassifier" href="#LLMTextAnalysis.TrainedClassifier"><code>LLMTextAnalysis.TrainedClassifier</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TrainedClassifier</code></pre><p>The <code>TrainedClassifier</code> struct is used for representing and working with a trained classification model, ie, it selects the most appropriate <code>label</code> for a given document.</p><p>It encapsulates all the necessary information required to analyze and score documents based on their relevance to a specific concept.</p><p><strong>Fields</strong></p><ul><li><code>index_id</code>: A unique identifier for the <code>AbstractDocumentIndex</code> associated with this concept.</li><li><code>source_doc_ids</code>: Indices of the documents from the <code>AbstractDocumentIndex</code> used for training the concept model. Corresponds to <code>index.docs</code> if provided.</li><li><code>concept</code>: The specific concept (as a string) that this model is trained to analyze.</li><li><code>docs</code>: The collection of rewritten documents, which are modified to reflect the concept.</li><li><code>embeddings</code>: The embeddings of the rewritten documents, used for training the model. Columns are documents, rows are dimensions.</li><li><code>coeffs</code>: The coefficients of the trained logistic regression model. Maps to each dimension in <code>embeddings</code>.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">index = build_index(...)

# Training a concept
concept = train_concept(index, &quot;sustainability&quot;)

# Using TrainedConcept for scoring
scores = score(index, concept)
# or use it as a functor: `scores = concept(index)`

# Accessing the model details
println(&quot;Concept: &quot;, concept.concept)
println(&quot;Coefficients: &quot;, concept.coeffs)
println(&quot;Source Document IDs: &quot;, concept.source_doc_ids)
println(&quot;Re-written Documents: &quot;, concept.docs) # good for debugging if results are poor</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/types.jl#L212-L247">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.TrainedClassifier-Tuple{LLMTextAnalysis.AbstractDocumentIndex}" href="#LLMTextAnalysis.TrainedClassifier-Tuple{LLMTextAnalysis.AbstractDocumentIndex}"><code>LLMTextAnalysis.TrainedClassifier</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">(classifier::TrainedClassifier)(
    index::AbstractDocumentIndex; check_index::Bool = true)</code></pre><p>A method definition that allows a <code>TrainedClassifier</code> object to be called as a function to score documents in an <code>index</code>. This method delegates to the <code>score</code> function.</p><p>The score reflects how closely each document aligns to each label in the trained classifier (<code>classifier.labels</code>). </p><p>The resulting scores will be a matrix of probabilities for each document and each label.</p><p>Scores dimension: <code>num_documents x num_labels</code>, ie, position [1,3] would correspond to the probability of the first document corresponding to the 3rd label/class.</p><p>To pick the best label for each document, you can use <code>argmax(scores, dims=2)</code>.</p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractDocumentIndex</code>: The index containing the documents to be scored.</li><li><code>return_labels::Bool</code> (optional): If <code>true</code>, returns the most probable labels instead of the scores. Defaults to <code>false</code>.</li><li><code>check_index::Bool</code> (optional): If <code>true</code>, performs a check to ensure that the index ID matches the one used in the classifier training. Defaults to <code>true</code>.</li></ul><p><strong>Returns</strong></p><ul><li>A vector of scores in the range [0, 1], each corresponding to a document in the index.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Assuming `index` and `classifier` are predefined
scores = classifier(index)</code></pre><p>Pick the highest scoring label for each document:</p><pre><code class="language-julia hljs">best_labels = score(index, classifier; return_labels = true)</code></pre><p>This method provides a convenient and intuitive way to apply a trained classifier model to a document index for scoring.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/classification.jl#L305-L339">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.TrainedConcept" href="#LLMTextAnalysis.TrainedConcept"><code>LLMTextAnalysis.TrainedConcept</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TrainedConcept</code></pre><p>The <code>TrainedConcept</code> struct is used for representing and working with a trained concept model.</p><p>It encapsulates all the necessary information required to analyze and score documents based on their relevance to a specific concept.</p><p><strong>Fields</strong></p><ul><li><code>index_id</code>: A unique identifier for the <code>AbstractDocumentIndex</code> associated with this concept.</li><li><code>source_doc_ids</code>: Indices of the documents from the <code>AbstractDocumentIndex</code> used for training the concept model. Corresponds to <code>index.docs</code></li><li><code>concept</code>: The specific concept (as a string) that this model is trained to analyze.</li><li><code>docs</code>: The collection of rewritten documents, which are modified to reflect the concept.</li><li><code>embeddings</code>: The embeddings of the rewritten documents, used for training the model. Columns are documents, rows are dimensions.</li><li><code>coeffs</code>: The coefficients of the trained logistic regression model. Maps to each dimension in <code>embeddings</code>.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">index = build_index(...)

# Training a concept
concept = train_concept(index, &quot;sustainability&quot;)

# Using TrainedConcept for scoring
scores = score(index, concept)
# or use it as a functor: `scores = concept(index)`

# Accessing the model details
println(&quot;Concept: &quot;, concept.concept)
println(&quot;Coefficients: &quot;, concept.coeffs)
println(&quot;Source Document IDs: &quot;, concept.source_doc_ids)
println(&quot;Re-written Documents: &quot;, concept.docs) # good for debugging if results are poor</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/types.jl#L112-L147">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.TrainedConcept-Tuple{LLMTextAnalysis.AbstractDocumentIndex}" href="#LLMTextAnalysis.TrainedConcept-Tuple{LLMTextAnalysis.AbstractDocumentIndex}"><code>LLMTextAnalysis.TrainedConcept</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">(concept::TrainedConcept)(index::AbstractDocumentIndex; check_index::Bool = true)</code></pre><p>A method definition that allows a <code>TrainedConcept</code> object to be called as a function to score documents in an <code>index</code>. This method delegates to the <code>score</code> function.</p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractDocumentIndex</code>: The index containing the documents to be scored.</li><li><code>check_index::Bool</code> (optional): If <code>true</code>, performs a check to ensure that the index ID matches the one used in the concept training. Defaults to <code>true</code>.</li></ul><p><strong>Returns</strong></p><ul><li>A vector of scores in the range [0, 1], each corresponding to a document in the index.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Assuming `index` and `concept` are predefined
scores = concept(index)</code></pre><p>This method provides a convenient and intuitive way to apply a trained concept model to a document index for scoring, facilitating thematic analysis and concept relevance studies.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/concept_labeling.jl#L635-L654">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.TrainedSpectrum" href="#LLMTextAnalysis.TrainedSpectrum"><code>LLMTextAnalysis.TrainedSpectrum</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TrainedSpectrum</code></pre><p>The <code>TrainedSpectrum</code> is used to score documents across a spectrum defined by two contrasting concepts. </p><p>It encapsulates the essential information required to evaluate and score documents based on their alignment with the specified spectrum.</p><p>Note: <code>TrainedSpectrum</code> supports functor behavior, allowing it to be used as a function to score documents in an <code>AbstractDocumentIndex</code> based on their alignment with the spectrum.</p><p><strong>Fields</strong></p><ul><li><code>index_id</code>: A unique identifier for the <code>AbstractDocumentIndex</code> associated with the spectrum.</li><li><code>source_doc_ids</code>: Indices of the documents from the <code>AbstractDocumentIndex</code> used for training the spectrum model. Corresponds to <code>index.docs</code>.</li><li><code>spectrum</code>: A tuple containing the two contrasting concepts (as strings) that define the spectrum.</li><li><code>docs</code>: A collection of rewritten documents, modified to align with the two ends of the spectrum.</li><li><code>embeddings</code>: The embeddings of the rewritten documents, used for training the model. Columns are documents, rows are dimensions.</li><li><code>coeffs</code>: Coefficients of the trained logistic regression model, corresponding to each dimension in <code>embeddings</code>.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">
index = build_index(...)

# Create and train a spectrum model
spectrum = TrainedSpectrum(index, (&quot;innovation&quot;, &quot;tradition&quot;))

# Using TrainedSpectrum for scoring
scores = score(index, concept)
# or use it as a functor: `scores = spectrum(index)`

# Accessing the model details
println(&quot;Spectrum: &quot;, spectrum.spectrum)
println(&quot;Coefficients: &quot;, spectrum.coeffs)
println(&quot;Source Document IDs: &quot;, spectrum.source_doc_ids)
println(&quot;Re-written Documents: &quot;, spectrum.docs) # good for debugging if results are poor</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/types.jl#L161-L198">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.TrainedSpectrum-Tuple{LLMTextAnalysis.AbstractDocumentIndex}" href="#LLMTextAnalysis.TrainedSpectrum-Tuple{LLMTextAnalysis.AbstractDocumentIndex}"><code>LLMTextAnalysis.TrainedSpectrum</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">(spectrum::TrainedSpectrum)(index::AbstractDocumentIndex; check_index::Bool = true)</code></pre><p>A method definition that allows a <code>TrainedSpectrum</code> object to be called as a function to score documents in an <code>index</code>. This method delegates to the <code>score</code> function.</p><p>The score reflects how closely each document aligns with each of the ends of the trained spectrum.  Scores are left-to-right, ie, a score closer to 0 indicates a higher alignment to <code>spectrum.spectrum[1]</code> and a score closer to 1 indicates a higher alignment to <code>spectrum.spectrum[2]</code>.</p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractDocumentIndex</code>: The index containing the documents to be scored.</li><li><code>check_index::Bool</code> (optional): If <code>true</code>, performs a check to ensure that the index ID matches the one used in the spectrum training. Defaults to <code>true</code>.</li></ul><p><strong>Returns</strong></p><ul><li>A vector of scores in the range [0, 1], each corresponding to a document in the index.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Assuming `index` and `spectrum` are predefined
scores = spectrum(index)</code></pre><p>This method provides a convenient and intuitive way to apply a trained spectrum model to a document index for scoring.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/concept_labeling.jl#L566-L588">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.build_clusters!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedClassifier}" href="#LLMTextAnalysis.build_clusters!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedClassifier}"><code>LLMTextAnalysis.build_clusters!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">build_clusters!(index::AbstractDocumentIndex, cls::TrainedClassifier;
    topic_level::AbstractString = &quot;&quot;,
    verbose::Bool = true, add_label::Bool = false, add_summary::Bool = false,
    labeler_kwargs::NamedTuple = NamedTuple())</code></pre><p>Builds topics based on the classifier&#39;s labels and labels all documents in the <code>index</code> with the highest probability label.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Assume `index` is already built and so is classifier `cls`
build_clusters!(index, cls; topic_level = &quot;MyClusters&quot;)

# Check that our new topic level is available
topic_levels(index) |&gt; keys</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/topic_modelling.jl#L330-L346">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.build_clusters!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, Vector{Int64}}" href="#LLMTextAnalysis.build_clusters!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, Vector{Int64}}"><code>LLMTextAnalysis.build_clusters!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">build_clusters!(index::AbstractDocumentIndex, assignments::Vector{Int};
    topic_level::AbstractString = &quot;&quot;,
    labels::Union{Vector{String}, Nothing} = nothing,
    verbose::Bool = true, add_label::Bool = false, add_summary::Bool = false,
    labeler_kwargs::NamedTuple = NamedTuple())</code></pre><p>Builds custom topics based on the provided <code>labels</code> and <code>assignments</code> (vector of which topic each document <code>index</code> belongs to).</p><p><strong>Arguments</strong></p><ul><li><code>index</code>: The document index.</li><li><code>assignments</code>: Vector of topic assignments for each document (eg, <code>[2,3]</code> -&gt; first document will be assigned to topic 2, second document will be assigned to topic 3).</li><li><code>topic_level</code>: The name of the topic level to create. If not provided, it will be autogenerated (eg, <code>Custom_1</code>).</li><li><code>labels</code>: Vector of labels for each topic if known. Otherwise, can be generated if you set <code>add_label=true</code>.</li><li><code>verbose</code>: Flag to enable INFO logging.</li><li><code>add_label</code>: Flag to enable topic labeling, ie, call LLM to generate topic label.</li><li><code>add_summary</code>: Flag to enable topic summarization, ie, call LLM to generate topic summary.</li><li><code>labeler_kwargs</code>: Keyword arguments to pass to the LLM labeler. See <code>?build_topic</code> for more details on available arguments.</li></ul><p><strong>Example</strong></p><p>Simple example with two clusters:</p><pre><code class="language-julia hljs">assignments = ones(Int,length(index.docs)) # which cluster each document belongs to
assignments[1:5] = 2 # first 5 documents belong to cluster 2

build_clusters!(index, assignments; topic_level=&quot;MyDualCluster&quot;, labels = [&quot;Cluster 1&quot;, &quot;Cluster 2&quot;])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/topic_modelling.jl#L246-L274">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.build_clusters!-Tuple{LLMTextAnalysis.AbstractDocumentIndex}" href="#LLMTextAnalysis.build_clusters!-Tuple{LLMTextAnalysis.AbstractDocumentIndex}"><code>LLMTextAnalysis.build_clusters!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">build_clusters!(index::AbstractDocumentIndex; k::Union{Int, Nothing} = nothing,
    h::Union{Float64, Nothing} = nothing,
    verbose::Bool = true, add_label::Bool = true, add_summary::Bool = false,
    labeler_kwargs::NamedTuple = NamedTuple(),
    cluster_kwargs...)</code></pre><p>Performs automatic clustering on the document index and builds topics at different levels.</p><p><strong>Arguments</strong></p><ul><li><code>index</code>: The document index.</li><li><code>k</code>: Number of clusters to cut at.</li><li><code>h</code>: Height to cut the dendrogram at. See <code>?Clustering.hclust</code> for more details.</li><li><code>verbose</code>: Flag to enable INFO logging.</li><li><code>add_label</code>: Flag to enable topic labeling, ie, call LLM to generate topic label.</li><li><code>add_summary</code>: Flag to enable topic summarization, ie, call LLM to generate topic summary.</li><li><code>labeler_kwargs</code>: Keyword arguments to pass to the LLM labeler. See <code>?build_topic</code> for more details on available arguments.</li><li><code>cluster_kwargs</code>: All remaining arguments will be passed to <code>Clustering.hclust</code>. See <code>?Clustering.hclust</code> for more details on available arguments.</li></ul><p><strong>Returns</strong></p><ul><li>The updated index with clustering information and topic metadata.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">index = build_index([&quot;Doc 1&quot;, &quot;Doc 2&quot;])
clustered_index = build_clusters!(index, k=2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/topic_modelling.jl#L146-L174">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.build_index-Tuple{Vector{&lt;:AbstractString}}" href="#LLMTextAnalysis.build_index-Tuple{Vector{&lt;:AbstractString}}"><code>LLMTextAnalysis.build_index</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">build_index(docs::Vector{&lt;:AbstractString}; verbose::Bool = true,
index_id::Symbol = gensym(&quot;DocIndex&quot;), aiembed_kwargs::NamedTuple = NamedTuple(),
keyword_kwargs::NamedTuple = NamedTuple(), kwargs...)</code></pre><p>Builds an index of the given documents, including their embeddings and extracted keywords.</p><p><strong>Arguments</strong></p><ul><li><code>docs</code>: Collection of documents to index. If you have only one large document, consider splitting it into smaller chunks with <code>PromptingTools.split_by_length</code>.</li><li><code>verbose</code>: Flag to enable INFO logging.</li><li><code>index_id</code>: Identifier for the document index. Useful if there will be multiple indices.</li><li><code>aiembed_kwargs</code>: Additional arguments for <code>PromptingTools.aiembed</code>. See <code>?aiembed</code> for more details.</li><li><code>keyword_kwargs</code>: Additional arguments for keyword extraction. See <code>?build_keywords</code> for more details.</li></ul><p><strong>Returns</strong></p><ul><li>An instance of <code>DocIndex</code> containing information about the documents, embeddings, keywords, etc.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">docs = [&quot;First document text&quot;, &quot;Second document text&quot;]
index = build_index(docs)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/preparation.jl#L74-L96">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.build_keywords" href="#LLMTextAnalysis.build_keywords"><code>LLMTextAnalysis.build_keywords</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">build_keywords(docs::Vector{&lt;:AbstractString},
    return_type::Type = String;
    min_length::Int = 2,
    stopwords::Vector{String} = stopwords(Languages.English()),
    stemmer_language::Union{Nothing, String} = &quot;english&quot;)</code></pre><p>Extracts and returns keywords from a collection of documents.</p><p><strong>Arguments</strong></p><ul><li><code>docs</code>: Collection of documents from which to extract keywords. If you have only one large document, consider splitting it into smaller chunks with <code>PromptingTools.split_by_length</code>.</li><li><code>return_type</code>: Element type of the returned keywords. Defaults to String.</li><li><code>min_length</code>: Minimum length of keywords to consider. Will be dropped if they are shorter than this.</li><li><code>stopwords</code>: List of stopwords to exclude from keyword extraction. Defaults to English stopwords (<code>stopwords(Languages.English())</code>).</li><li><code>stemmer_language</code>: Language for stemming, if applicable. Set to <code>nothing</code> to disable stemming.</li></ul><p><strong>Returns</strong></p><ul><li>A sparse matrix where each column represents a document and each row a keyword, weighted by its frequency.</li><li>A vector of unique keywords across all documents.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">docs = [&quot;Sample document text.&quot;, &quot;Another document.&quot;]
keywords_ids, keywords_vocab = build_keywords(docs)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/preparation.jl#L1-L26">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.build_topic-Tuple{LLMTextAnalysis.AbstractDocumentIndex, Vector{Int64}, Int64}" href="#LLMTextAnalysis.build_topic-Tuple{LLMTextAnalysis.AbstractDocumentIndex, Vector{Int64}, Int64}"><code>LLMTextAnalysis.build_topic</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">build_topic(
    index::AbstractDocumentIndex, assignments::Vector{Int}, topic_idx::Int;
    topic_level::Union{AbstractString, Int} = nunique(assignments),
    verbose::Bool = false, add_label::Bool = true, add_summary::Bool = false,
    label_template::Union{Nothing, Symbol} = :TopicLabelerBasic,
    label_default::AbstractString = &quot;&quot;,
    summary_template::Union{Nothing, Symbol} = :TopicSummarizerBasic,
    summary_default::AbstractString = &quot;&quot;,
    num_samples::Int = 8, num_keywords::Int = 10,
    cost_tracker::Union{Nothing, Threads.Atomic{Float64}} = nothing, aikwargs...)</code></pre><p>Builds the metadata for a specific topic in the document index.</p><p><strong>Arguments</strong></p><ul><li><code>index</code>: The document index.</li><li><code>assignments</code>: Vector of topic assignments for each document.</li><li><code>topic_idx</code>: Index of the topic to build metadata for.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>topic_level</code>: The level of the topic in the hierarchy. Corresponds to <code>k::Int</code> in <code>build_clusters!</code> or a String-based label for custom topics.</li><li><code>verbose</code>: Flag to enable INFO logging.</li><li><code>add_label</code>: Flag to enable topic labeling, ie, call LLM to generate topic label.</li><li><code>add_summary</code>: Flag to enable topic summarization, ie, call LLM to generate topic summary.</li><li><code>label_default</code>: Default label to use if no label is generated. It can be used to directly provide a label.</li><li><code>summary_default</code>: Default summary to use if no summary is generated. It can be used to directly provide a summary.</li><li><code>label_template</code>: The LLM template to use for topic labeling. See <code>?aitemplates</code> for more details on templates.</li><li><code>summary_template</code>: The LLM template to use for topic summarization. See <code>?aitemplates</code> for more details on templates.</li><li><code>num_samples</code>: Number of diverse samples to show to the LLM for each topic.</li><li><code>num_keywords</code>: Number of top keywords to show to the LLM for each topic.</li><li><code>cost_tracker</code>: An <code>Atomic</code> to track the cost of the LLM calls, if we trigger multiple calls asynchronously.</li></ul><p><strong>Returns</strong></p><ul><li><code>TopicMetadata</code> instance for the specified topic.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">index = build_index([&quot;Document 1&quot;, &quot;Document 2&quot;])
assignments = [1, 1]
metadata = build_topic(index, assignments, 1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/topic_modelling.jl#L1-L43">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.create_folds-Tuple{Integer, Integer}" href="#LLMTextAnalysis.create_folds-Tuple{Integer, Integer}"><code>LLMTextAnalysis.create_folds</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">create_folds(k::Int, data_size::Int)</code></pre><p>Create <code>k</code> random folds from a dataset of size <code>data_size</code>.</p><p><strong>Arguments</strong></p><ul><li><code>k::Int</code>: Number of folds to create.</li><li><code>n_obs::Int</code>: Total number of observations in the dataset.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{SubArray}</code>: A vector of <code>k</code> vectors, each containing indices for a fold.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs"># Create 4 folds from a dataset Xt
n_obs = size(Xt, 1)
folds = create_folds(4, n_obs)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/concept_labeling.jl#L6-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.cross_validate_accuracy-Tuple{AbstractMatrix, AbstractVector{&lt;:Integer}}" href="#LLMTextAnalysis.cross_validate_accuracy-Tuple{AbstractMatrix, AbstractVector{&lt;:Integer}}"><code>LLMTextAnalysis.cross_validate_accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">cross_validate_accuracy(X::AbstractMatrix{&lt;:Number},
                        y::AbstractVector{&lt;:Integer};
                        verbose::Bool = true,
                        k::Int = 4,
                        lambda::Real = 1e-5) -&gt; Float64</code></pre><p>Perform k-fold cross-validation on the dataset <code>(X, y)</code> using logistic regression  and return the average classification accuracy.</p><p><strong>Arguments</strong></p><ul><li><code>X::AbstractMatrix</code>: The feature matrix (observarions x features).</li><li><code>y::AbstractVector{&lt;:Integer}</code>: The target vector (+-1)</li><li><code>verbose::Bool</code> (optional): If <code>true</code>, prints the accuracy of each fold. Defaults to <code>true</code>.</li><li><code>k::Int</code> (optional): The number of folds for cross-validation. Defaults to 4.</li><li><code>lambda::Real</code> (optional): Regularization parameter for logistic regression. Defaults to 1e-5.</li></ul><p><strong>Returns</strong></p><ul><li><code>Float64</code>: The average classification accuracy across all folds.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">acc = cross_validate_accuracy(Xt, y; k = 4, lambda = 1e-2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/concept_labeling.jl#L34-L58">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.nunique-Tuple{AbstractVector}" href="#LLMTextAnalysis.nunique-Tuple{AbstractVector}"><code>LLMTextAnalysis.nunique</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Counts number of unique elements in a vector</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/utils.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.prepare_plot!-Tuple{LLMTextAnalysis.AbstractDocumentIndex}" href="#LLMTextAnalysis.prepare_plot!-Tuple{LLMTextAnalysis.AbstractDocumentIndex}"><code>LLMTextAnalysis.prepare_plot!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">prepare_plot!(index::AbstractDocumentIndex; verbose::Bool=true, kwargs...) -&gt; AbstractDocumentIndex</code></pre><p>Prepares the 2D UMAP plot data for a given document index.</p><p><strong>Arguments</strong></p><ul><li><code>index</code>: The document index to prepare plot data for.</li><li><code>verbose</code>: Flag to enable INFO logging.</li></ul><p><strong>Returns</strong></p><ul><li>The updated index with <code>plot_data</code> field populated.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">index = build_index([&quot;Some text&quot;, &quot;More text&quot;])
prepared_index = prepare_plot!(index)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/preparation.jl#L135-L152">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.score-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedClassifier}" href="#LLMTextAnalysis.score-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedClassifier}"><code>LLMTextAnalysis.score</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">score(index::AbstractDocumentIndex,
    classifier::TrainedClassifier;
    check_index::Bool = true)</code></pre><p>Scores all documents in the provided <code>index</code> based on the <code>TrainedClassifier</code>. </p><p>The score reflects how closely each document aligns to each label in the trained classifier (<code>classifier.labels</code>). </p><p>The resulting scores will be a matrix of probabilities for each document and each label.</p><p>Scores dimension: <code>num_documents x num_labels</code>, ie, position [1,3] would correspond to the probability of the first document corresponding to the 3rd label/class.</p><p>To pick the best label for each document, you can use <code>argmax(scores, dims=2)</code>.</p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractDocumentIndex</code>: The index containing the documents to be scored.</li><li><code>classifier::TrainedClassifier</code>: The trained classifier model used for scoring.</li><li><code>return_labels::Bool</code> (optional): If <code>true</code>, returns the most probable labels instead of the scores. Defaults to <code>false</code>.</li><li><code>check_index::Bool</code> (optional): If <code>true</code>, checks for index ID matching between the provided index and the one used in the classifier training. Defaults to <code>true</code>.</li></ul><p><strong>Returns</strong></p><ul><li>A matrix of scores, each row corresponding to a document in the index and each column corresponding to probability of that label.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Assuming `index` and `classifier` are predefined
scores = score(index, classifier)</code></pre><p>Pick the highest scoring label for each document:</p><pre><code class="language-julia hljs">scores = score(index, classifier)
label_ids = argmax(scores, dims = 2) |&gt; vec |&gt; x -&gt; map(i -&gt; i[2], x)
best_labels = classifier.labels[label_ids]</code></pre><p>Or, instead, you can simply provide <code>return_labels=true</code> to get the best labels directly:</p><pre><code class="language-julia hljs">score(index, classifier; return_labels = true)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/classification.jl#L241-L283">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.score-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedConcept}" href="#LLMTextAnalysis.score-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedConcept}"><code>LLMTextAnalysis.score</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">score(index::AbstractDocumentIndex, concept::TrainedConcept; check_index::Bool = true)</code></pre><p>Scores all documents in the provided <code>index</code> based on the <code>TrainedConcept</code>. </p><p>The score quantifies the relevance or alignment of each document with the trained concept, with a score closer to 1 indicating a higher relevance.</p><p>The function uses a sigmoid function to map the scores to a range between 0 and 1, providing a probability-like interpretation.</p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractDocumentIndex</code>: The index containing the documents to be scored.</li><li><code>concept::TrainedConcept</code>: The trained concept model used for scoring.</li><li><code>check_index::Bool</code> (optional): If <code>true</code>, checks for index ID matching between the provided index and the one used in the concept training. Defaults to <code>true</code>.</li></ul><p><strong>Returns</strong></p><ul><li>A vector of scores, each corresponding to a document in the index, in the range [0, 1].</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Assuming `index` and `concept` are predefined
scores = score(index, concept)</code></pre><p>You can show the top 5 highest scoring documents for the concept:</p><pre><code class="language-julia hljs">index.docs[first(sortperm(scores, rev = true), 5)]</code></pre><p>This function is particularly useful for analyzing the presence, intensity, or relevance of a specific concept within a collection of documents.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/concept_labeling.jl#L593-L622">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.score-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedSpectrum}" href="#LLMTextAnalysis.score-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedSpectrum}"><code>LLMTextAnalysis.score</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">score(index::AbstractDocumentIndex,
    spectrum::TrainedSpectrum;
    check_index::Bool = true)</code></pre><p>Scores all documents in the provided <code>index</code> based on the <code>TrainedSpectrum</code>. </p><p>The score reflects how closely each document aligns with each of the ends of the trained spectrum.  Scores are left-to-right, ie, a score closer to 0 indicates a higher alignment to <code>spectrum.spectrum[1]</code> and a score closer to 1 indicates a higher alignment to <code>spectrum.spectrum[2]</code>.</p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractDocumentIndex</code>: The index containing the documents to be scored.</li><li><code>spectrum::TrainedSpectrum</code>: The trained spectrum model used for scoring.</li><li><code>check_index::Bool</code> (optional): If <code>true</code>, checks for index ID matching between the provided index and the one used in the spectrum training. Defaults to <code>true</code>.</li></ul><p><strong>Returns</strong></p><ul><li>A vector of scores, each corresponding to a document in the index, in the range [0, 1].</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Assuming `index` and `spectrum` are predefined
scores = score(index, spectrum)</code></pre><p>You can show the top 5 highest scoring documents for the spectrum 2:</p><pre><code class="language-julia hljs">index.docs[first(sortperm(scores, rev = true), 5)]

# Use rev=false if you want to see documents closest to spectrum 1 (opposite end)</code></pre><p>This function is useful for ranking all documents along the chosen <code>spectrum</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/concept_labeling.jl#L521-L553">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.train!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedClassifier}" href="#LLMTextAnalysis.train!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedClassifier}"><code>LLMTextAnalysis.train!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">train!(index::AbstractDocumentIndex,
    classifier::TrainedClassifier;
    verbose::Bool = true,
    overwrite::Bool = false,
    writer_template::Symbol = :TextWriterFromLabel,
    lambda::Real = 1e-3, num_samples::Int = 5,
    aigenerate_kwargs::NamedTuple = NamedTuple(),
    aiembed_kwargs::NamedTuple = NamedTuple())</code></pre><p>Refine or retrain a previously trained <code>TrainedClassifier</code> model. </p><p>This function can be used to update the classifier model with new data, adjust parameters, or completely retrain it.</p><p>See also: <code>train_classifier</code>, <code>score</code></p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractDocumentIndex</code>: The document index containing the documents for analysis.</li><li><code>classifier::TrainedClassifier</code>: The trained classifier object to be refined or retrained.</li><li><code>verbose::Bool</code> (optional): If <code>true</code>, prints detailed logs during the process. Defaults to <code>true</code>.</li><li><code>overwrite::Bool</code> (optional): If <code>true</code>, existing training data in the classifier will be overwritten. Defaults to <code>false</code>.</li><li><code>writer_template::Symbol</code> (optional): The template used for writing synthetic documents. Defaults to <code>:TextWriterFromLabel</code>.</li><li><code>lambda::Real</code> (optional): Regularization parameter for logistic regression. Defaults to 1e-3.</li><li><code>num_samples::Int</code> (optional): The number of examples to to generate for each topic label. Defaults to 5.</li><li><code>aigenerate_kwargs::NamedTuple</code> (optional): Additional arguments for the <code>aigenerate</code> function.</li><li><code>aiembed_kwargs::NamedTuple</code> (optional): Additional arguments for the <code>aiembed</code> function.</li></ul><p><strong>Returns</strong></p><ul><li>The updated <code>TrainedClassifier</code> object with refined or new training.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Assuming `index` and `classifier` are pre-existing objects
train!(index, classifier, verbose = true, overwrite = true)</code></pre><p>This function allows for continuous improvement and adaptation of a classifier model to new data. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/classification.jl#L127-L164">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.train!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedConcept}" href="#LLMTextAnalysis.train!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedConcept}"><code>LLMTextAnalysis.train!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">train!(index::AbstractDocumentIndex,
       concept::TrainedConcept;
       verbose::Bool = true,
       overwrite::Bool = false,
       rewriter_template::Symbol = :StatementRewriter,
       lambda::Real = 1e-3, negatives_samples::Int = 1,
       aigenerate_kwargs::NamedTuple = NamedTuple(),
       aiembed_kwargs::NamedTuple = NamedTuple(),)</code></pre><p>Refine or retrain a previously trained <code>TrainedConcept</code> model. </p><p>This function can be used to update the concept model with new data, adjust parameters, or completely retrain it.</p><p>See also: <code>train_concept</code>, <code>score</code></p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractDocumentIndex</code>: The document index containing the documents for analysis.</li><li><code>concept::TrainedConcept</code>: The trained concept object to be refined or retrained.</li><li><code>verbose::Bool</code> (optional): If <code>true</code>, prints detailed logs during the process. Defaults to <code>true</code>.</li><li><code>overwrite::Bool</code> (optional): If <code>true</code>, existing training data in the concept will be overwritten. Defaults to <code>false</code>.</li><li><code>rewriter_template::Symbol</code> (optional): The template used for rewriting statements. Defaults to <code>:StatementRewriter</code>.</li><li><code>lambda::Real</code> (optional): Regularization parameter for logistic regression. Defaults to 1e-3.</li><li><code>negatives_samples::Int</code> (optional): The number of negative examples to use for training per each positive sample. Defaults to 1.</li><li><code>aigenerate_kwargs::NamedTuple</code> (optional): Additional arguments for the <code>aigenerate</code> function.</li><li><code>aiembed_kwargs::NamedTuple</code> (optional): Additional arguments for the <code>aiembed</code> function.</li></ul><p><strong>Returns</strong></p><ul><li>The updated <code>TrainedConcept</code> object with refined or new training.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Assuming `index` and `concept` are pre-existing objects
concept = train!(index, concept, verbose = true, overwrite = true)</code></pre><p>This function allows for continuous improvement and adaptation of a concept model to new data or analysis perspectives. It is particularly useful in dynamic environments where the underlying data or the concept of interest may evolve over time.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/concept_labeling.jl#L175-L212">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.train!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedSpectrum}" href="#LLMTextAnalysis.train!-Tuple{LLMTextAnalysis.AbstractDocumentIndex, TrainedSpectrum}"><code>LLMTextAnalysis.train!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">train!(index::AbstractDocumentIndex,
       spectrum::TrainedSpectrum;
       verbose::Bool = true,
       overwrite::Bool = false,
       rewriter_template::Symbol = :StatementRewriter,
       lambda::Real = 1e-5,
       aigenerate_kwargs::NamedTuple = NamedTuple(),
       aiembed_kwargs::NamedTuple = NamedTuple(),)</code></pre><p>Finish a partially trained Spectrum or retrain an existing one (with <code>overwrite=true</code>).</p><p>See also: <code>train_spectrum</code>, <code>train_concept</code>, <code>score</code></p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractDocumentIndex</code>: The document index containing the documents to be analyzed.</li><li><code>spectrum::TrainedSpectrum</code>: The previously trained spectrum object to be trained.</li><li><code>verbose::Bool</code> (optional): If <code>true</code>, prints logs during the process. Defaults to <code>true</code>.</li><li><code>overwrite::Bool</code> (optional): If <code>true</code>, existing training data in the spectrum will be overwritten. Defaults to <code>false</code>.</li><li><code>rewriter_template::Symbol</code> (optional): The template used for rewriting statements. Defaults to <code>:StatementRewriter</code>.</li><li><code>lambda::Real</code> (optional): Regularization parameter for logistic regression. Defaults to 1e-5. Reduce if your cross-validated accuracy is too low.</li><li><code>aigenerate_kwargs::NamedTuple</code> (optional): Additional arguments for the <code>aigenerate</code> function. See <code>?aigenerate</code> for more details.</li><li><code>aiembed_kwargs::NamedTuple</code> (optional): Additional arguments for the <code>aiembed</code> function. See <code>?aiembed</code> for more details.</li></ul><p><strong>Returns</strong></p><ul><li>The updated <code>TrainedSpectrum</code> object containing the trained model (<code>coeffs</code>), along with other relevant information like the rewritten document (<code>docs</code>) and embeddings (<code>embeddings</code>).</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Assuming `index` and `spectrum` are pre-existing objects
trained_spectrum = train!(index, spectrum, verbose = true, overwrite = true)</code></pre><p>This function allows for iterative improvement of a spectrum model, adapting to new data or refinements in the analysis framework.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/concept_labeling.jl#L391-L425">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.train_classifier-Tuple{LLMTextAnalysis.AbstractDocumentIndex, AbstractVector{&lt;:AbstractString}}" href="#LLMTextAnalysis.train_classifier-Tuple{LLMTextAnalysis.AbstractDocumentIndex, AbstractVector{&lt;:AbstractString}}"><code>LLMTextAnalysis.train_classifier</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">train_classifier(index::AbstractDocumentIndex,
    labels::AbstractVector{&lt;:AbstractString};
    docs_ids::AbstractVector{&lt;:Integer} = Int[],
    docs_labels::AbstractVector{&lt;:Integer} = Int[],
    labels_description::Union{Nothing, AbstractVector{&lt;:AbstractString}} = nothing,
    num_samples::Int = 5, verbose::Bool = true,
    writer_template::Symbol = :TextWriterFromLabel,
    lambda::Real = 1e-3,
    aigenerate_kwargs::NamedTuple = NamedTuple(),
    aiembed_kwargs::NamedTuple = NamedTuple())</code></pre><p>Train a model to classify each document into one of several specific topics based on <code>labels</code> (detailed in <code>labels_description</code>).</p><p>If user provides documents from the index and their corresponding labels (<code>docs_ids</code> and <code>docs_labels</code>, respectively),  the model will be trained on those documents. Aim for a balanced dataset (all <code>labels</code> must be present) and a minimum of 5 documents per label (ideally more).</p><p>Otherwise, we will first generate <code>num_samples</code> of synthetic documents for each label in <code>labels</code>, ie, in total there will be <code>num_samples x length(labels)</code> generated documents. If <code>labels_description</code> is provided, these descriptions will be provided to the AI model to generate more diverse and relevant documents for each label (more informative than just one word labels).</p><p>Under the hood, we train a multi-label classifier on top of the embeddings of the documents.</p><p>The resulting scores will be a matrix of probabilities for each document and each label. Scores dimension: <code>num_documents x num_labels</code>, ie, position [1,3] would correspond to the probability of the first document corresponding to the 3rd label/class. To pick the best label for each document, you can use <code>argmax(scores, dims=2)</code>.</p><p>See also: <code>score</code>, <code>train!</code>, <code>train_spectrum</code>, <code>train_concept</code></p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractDocumentIndex</code>: An index containing the documents to be analyzed.</li><li><code>labels::AbstractVector{&lt;:AbstractString}</code>: A vector of labels to be used for training the classifier (documents will be assigned to one of these labels).</li><li><code>docs_ids::AbstractVector{&lt;:Integer}</code> (optional): The IDs of the documents in the <code>index</code> to be used for training. Defaults to an empty vector and will generate synthetic documents.</li><li><code>docs_labels::AbstractVector{&lt;:Integer}</code> (optional): The labels corresponding to the documents in <code>docs_ids</code>. Defaults to an empty vector.</li><li><code>labels_description::Union{Nothing, AbstractVector{&lt;:AbstractString}}</code> (optional): A vector of descriptions for each label. If provided, it will be used to generate more diverse and relevant documents for each label. Defaults to <code>nothing</code>.</li><li><code>num_samples::Int</code> (optional): The number of documents to generate for each label in <code>labels</code>. Defaults to 5.</li><li><code>verbose::Bool</code> (optional): If <code>true</code>, prints detailed logs during the process. Defaults to <code>true</code>.</li><li><code>writer_template::Symbol</code> (optional): The template used for writing synthetic documents. Defaults to <code>:TextWriterFromLabel</code>.</li><li><code>lambda::Real</code> (optional): Regularization parameter for logistic regression. Defaults to 1e-3</li><li><code>aigenerate_kwargs::NamedTuple</code> (optional): Additional arguments for the <code>aigenerate</code> function. See <code>?aigenerate</code> for more details.</li><li><code>aiembed_kwargs::NamedTuple</code> (optional): Additional arguments for the <code>aiembed</code> function. See <code>?aiembed</code> for more details.</li></ul><p><strong>Returns</strong></p><ul><li>A <code>TrainedClassifier</code> object containing the trained model, along with relevant information such as the generated documents (<code>docs</code>), embeddings (<code>embeddings</code>), and model coefficients (<code>coeffs</code>).</li></ul><p><strong>Example</strong></p><p>Create a classifier for a set of labeled documents in our index (ie, we know the labels for some documents):</p><pre><code class="language-julia hljs"># Assuming `index` is an existing document index

# Provide the names of the topics and corresponding labeled documents
labels = [&quot;Improving traffic situation&quot;, &quot;Taxes and public funding&quot;,
    &quot;Safety and community&quot;, &quot;Other&quot;]

# Let&#39;s say we have labeled a few documents - ideally, you should have 5-10 examples for EACH label
docs_ids = [1, 2674, 4, 17, 23, 69, 2669, 6]
docs_labels = [1, 1, 2, 2, 3, 3, 4, 4] # what topic each doc belongs to

# Train the classifier
cls = train_classifier(index, labels; docs_ids, docs_labels)

# Score the documents in the index
score(index, cls) # or cls(index)</code></pre><p>If you do not have any labeled documents, you can ask an AI model to generate some potential examples for you (<code>num_samples</code> per each topic/label). It helps to provide label descriptions to improve the quality of generated documents:</p><pre><code class="language-julia hljs"># Assuming `index` is an existing document index

labels_description = [
    &quot;Survey responses around infrastructure, improving traffic situation and related&quot;,
    &quot;Decreasing taxes and giving more money to the community&quot;,
    &quot;Survey responses around Homelessness, general safety and community related topics&quot;,
    &quot;Any other topics like environment, education, governance, etc.&quot;]

# Train the classifier - it will generate 20 document examples (5 for each label x 4 labels)
cls = train_classifier(index, labels; labels_description, num_samples=5)

# Get scores for all documents
scores = score(index, cls)

# Get labels for all documens in the index
best_labels = score(index, cls; return_labels = true)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/classification.jl#L2-L88">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.train_concept-Tuple{LLMTextAnalysis.AbstractDocumentIndex, String}" href="#LLMTextAnalysis.train_concept-Tuple{LLMTextAnalysis.AbstractDocumentIndex, String}"><code>LLMTextAnalysis.train_concept</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">train_concept(index::AbstractDocumentIndex,
              concept::String;
              num_samples::Int = 100, verbose::Bool = true,
              rewriter_template::Symbol = :StatementRewriter,
              lambda::Real = 1e-3, negatives_samples::Int = 1,
              aigenerate_kwargs::NamedTuple = NamedTuple(),
              aiembed_kwargs::NamedTuple = NamedTuple(),)</code></pre><p>Train a model to identify and score a specific Concept (defined by the string <code>concept</code>) based on <code>num_samples documents from</code>index`.</p><p>We effectively identify the &quot;direction&quot; in the embedding space that represent this concept and develop a model to be able to score our documents against it.</p><p>This function focuses on a single Concept, as opposed to a Spectrum (see <code>train_spectrum</code>), to gauge its presence, strength, or manifestations in the documents.</p><p>See also: <code>train_spectrum</code>, <code>train!</code>, <code>score</code></p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractDocumentIndex</code>: An index containing the documents to be analyzed.</li><li><code>concept::String</code>: The concept to be analyzed within the documents.</li><li><code>num_samples::Int</code> (optional): The number of documents to sample from the index for training. Defaults to 100.</li><li><code>verbose::Bool</code> (optional): If <code>true</code>, prints detailed logs during the process. Defaults to <code>true</code>.</li><li><code>rewriter_template::Symbol</code> (optional): The template used for rewriting statements. Defaults to <code>:StatementRewriter</code>.</li><li><code>lambda::Real</code> (optional): Regularization parameter for logistic regression. Defaults to 1e-3</li><li><code>negatives_samples::Int</code> (optional): The number of negative examples to use for training per each positive sample. Defaults to 1.</li><li><code>aigenerate_kwargs::NamedTuple</code> (optional): Additional arguments for the <code>aigenerate</code> function. See <code>?aigenerate</code> for more details.</li><li><code>aiembed_kwargs::NamedTuple</code> (optional): Additional arguments for the <code>aiembed</code> function. See <code>?aiembed</code> for more details.</li></ul><p><strong>Returns</strong></p><ul><li>A <code>TrainedConcept</code> object containing the trained model, along with relevant information such as rewritten documents (<code>docs</code>), embeddings (<code>embeddings</code>), and model coefficients (<code>coeffs</code>).</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Assuming `index` is an existing document index
my_concept = &quot;sustainability&quot;
concept_model = train_concept(index, my_concept)</code></pre><p>Show the top 5 highest scoring documents for the concept:</p><pre><code class="language-julia hljs">scores = score(index, concept)
index.docs[first(sortperm(scores, rev = true), 5)]</code></pre><p>You can customize the training by passing additional arguments to the AI generation and embedding functions. For example, you can specify the model to use for generation and how many samples to use:</p><pre><code class="language-julia hljs">concept = train_concept(index,
    &quot;action-oriented&quot;;
    num_samples = 50,
    aigenerate_kwargs = (; model = &quot;gpt3t&quot;))</code></pre><p>This function leverages large language models to extract and analyze the presence and variations of a specific concept within a document corpus. It can be particularly useful in thematic studies, sentiment analysis, or trend identification in large collections of text.</p><p>For further analysis, you can inspect the rewritten documents and their embeddings:</p><pre><code class="language-julia hljs"># Concept-related rewritten documents
concept_model.docs

# Embeddings of the rewritten documents
concept_model.embeddings</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/concept_labeling.jl#L92-L155">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.train_spectrum-Tuple{LLMTextAnalysis.AbstractDocumentIndex, Tuple{String, String}}" href="#LLMTextAnalysis.train_spectrum-Tuple{LLMTextAnalysis.AbstractDocumentIndex, Tuple{String, String}}"><code>LLMTextAnalysis.train_spectrum</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">train_spectrum(index::AbstractDocumentIndex,
    spectrum::Tuple{String, String};
    num_samples::Int = 100, verbose::Bool = true,
    rewriter_template::Symbol = :StatementRewriter,
    lambda::Real = 1e-5,
    aigenerate_kwargs::NamedTuple = NamedTuple(),
    aiembed_kwargs::NamedTuple = NamedTuple(),)</code></pre><p>Train a Spectrum, ie, a two-sided axis of polar opposite concepts.</p><p>We effectively identify the &quot;directions&quot; in the embedding space that represent the two concepts that you selected as the opposite ends of the spectrum.</p><p>Practically, it takes a <code>num_samples</code> documents from <code>index</code>, rewrites them through the specified lenses (ends of spectrum), then embeds these rewritten documents, and finally trains a logistic regression model to classify the documents according to the spectrum.</p><p>See also: <code>train!</code>, <code>train_concept</code>, <code>score</code></p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractDocumentIndex</code>: An index containing the documents to be analyzed. This index should have been previously built using <code>build_index</code>.</li><li><code>spectrum::Tuple{String, String}</code>: A pair of strings representing the two lenses through which the documents will be rewritten. For example, (&quot;optimistic&quot;, &quot;pessimistic&quot;) could be a spectrum.</li><li><code>num_samples::Int</code> (optional): The number of documents to sample from the index for training. Defaults to 100.</li><li><code>verbose::Bool</code> (optional): If <code>true</code>, prints detailed logs during the process. Defaults to <code>true</code>.</li><li><code>rewriter_template::Symbol</code> (optional): The template used for rewriting statements. Defaults to <code>:StatementRewriter</code>.</li><li><code>lambda::Real</code> (optional): Regularization parameter for the logistic regression. Defaults to 1e-5. Adjust if your cross-validated accuracy is too low.</li><li><code>aigenerate_kwargs::NamedTuple</code> (optional): Additional arguments for the <code>aigenerate</code> function. See <code>?aigenerate</code> for more details.</li><li><code>aiembed_kwargs::NamedTuple</code> (optional): Additional arguments for the <code>aiembed</code> function. See <code>?aiembed</code> for more details.</li></ul><p><strong>Returns</strong></p><ul><li>A <code>TrainedSpectrum</code> object containing the trained model (<code>coeffs</code>), along with other relevant information like the rewritten document (<code>docs</code>) and embeddings (<code>embeddings</code>).</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Assuming `index` is an existing document index
my_spectrum = (&quot;pessimistic&quot;, &quot;optimistic&quot;)
spectrum = train_spectrum(index, my_spectrum)</code></pre><p>Show the top 5 highest scoring documents for the spectrum 2 (<code>spectrum.spectrum[2]</code> which is &quot;optimistic&quot; in this example):</p><pre><code class="language-julia hljs">scores = score(index, spectrum)
index.docs[first(sortperm(scores, rev = true), 5)]

# Use rev=false to get the highest scoring documents for spectrum 1 (opposite end)</code></pre><p>You can customize the analysis by passing additional arguments to the AI generation and embedding functions. For example, you can specify the model to use for generation and how many samples to use:</p><pre><code class="language-julia hljs">spectrum = train_spectrum(index,
    (&quot;forward-looking&quot;, &quot;dwelling in the past&quot;);
    num_samples = 50, aigenerate_kwargs = (; model = &quot;gpt3t&quot;))</code></pre><p>This function utilizes large language models to rewrite and analyze the text, providing insights based on the specified spectrum. The output includes embeddings and a model capable of projecting new documents onto this spectrum for analysis.</p><p>For troubleshooting, you can fit the model manually and inspect the accuracy:</p><pre><code class="language-julia hljs">X = spectrum.embeddings&#39;
# First half is spectrum 1, second half is spectrum 2
y = vcat(-1ones(length(spectrum.source_doc_ids)), ones(length(spectrum.source_doc_ids))) .|&gt;
    Int
accuracy = cross_validate_accuracy(X, y; k = 4, lambda = 1e-8)</code></pre><p>Or explore the source documents and re-written documents:</p><pre><code class="language-julia hljs"># source documents
index.docs[spectrum.source_doc_ids]

# re-written documents
spectrum.docs</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/concept_labeling.jl#L298-L371">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LLMTextAnalysis.wrap_string" href="#LLMTextAnalysis.wrap_string"><code>LLMTextAnalysis.wrap_string</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">wrap_string(str::String,
    text_width::Int = 20;
    newline::Union{AbstractString, AbstractChar} = &#39;</code></pre><p>&#39;)</p><p>Breaks a string into lines of a given <code>text_width</code>. Optionally, you can specify the <code>newline</code> character or string to use.</p><p><strong>Example:</strong></p><pre><code class="language-julia hljs">wrap_string(&quot;Certainly, here&#39;s a function in Julia that will wrap a string according to the specifications:&quot;, 10) |&gt; print</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/LLMTextAnalysis.jl/blob/246a6284bae2492ab651e13e1551c039bf0784f2/src/utils.jl#L18-L32">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../FAQ/">« F.A.Q.</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Wednesday 6 March 2024 13:27">Wednesday 6 March 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
